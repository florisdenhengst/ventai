{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections.abc import Iterable\n",
    "import functools\n",
    "import itertools\n",
    "import operator\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('pgf')\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",  # use serif/main font for text elements\n",
    "    \"text.usetex\": True,     # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,    # don't setup fonts from rc parameters\n",
    "    \"text.latex.preamble\":  [r\"\"\"\\usepackage{amssymb}\"\"\", r'\\usepackage{amsmath}'],\n",
    "    })\n",
    "# mpl.verbose.level = 'debug-annoying'\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import numpy_ext as npe\n",
    "import math\n",
    "import random\n",
    "from pprint import pprint\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import poisson\n",
    "from scipy.sparse import hstack, vstack, csr_matrix\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import utils\n",
    "import sys\n",
    "\n",
    "from config import demographics, vital_sign_vars, lab_vars, treatment_vars, vent_vars, guideline_vars, ffill_windows_clinical, SAMPLE_TIME_H\n",
    "from config import fio2_bins, peep_bins, tv_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/ope_results.csv'\n",
    "safety_file = 'data/safety_results.csv'\n",
    "ope_wis = pd.read_csv(file)\n",
    "safety = pd.read_csv(safety_file)\n",
    "\n",
    "ope_wis = pd.merge(ope_wis, safety, suffixes=['', '_left',], on=['seed', 'algorithm', 'unsafety_prob_train', 'shaping', 'safety', 'scalar'])\n",
    "\n",
    "REWARD_RANGE = (-100, 100)\n",
    "RR_SIZE = max(REWARD_RANGE) - min(REWARD_RANGE)\n",
    "N_BOOT = 2000\n",
    "\n",
    "# TEXTWIDTH=390.0 # AI in MEDICINE\n",
    "TEXTWIDTH=341.43289 # Dissertation\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('behavior', 'IL')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('observed', 'O')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('softmax', 'QL$_S$')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('greedy', 'QL$_D$')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('mixed', 'M')\n",
    "    \n",
    "ope_wis['norm_scalar'] = ope_wis['scalar'] / RR_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ope_wis = ope_wis[ope_wis.algorithm != 'G']\n",
    "# ope_wis = ope_wis[ope_wis.seed < 10]\n",
    "# ope_wis = ope_wis[ope_wis.unsafety_prob_train == 1.0]\n",
    "# ope_wis = ope_wis[ope_wis.norm_scalar == 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgpotential2    720\n",
       "none             180\n",
       "Name: shaping, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ope_wis.shaping.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = ope_wis.seed.unique()\n",
    "# algorithms = ope_wis.algorithm.unique()\n",
    "# settings = ope_wis.train_test.unique()\n",
    "# shaping = ope_wis.shaping.unique()\n",
    "\n",
    "# experiments = itertools.product(seeds, algorithms, settings)\n",
    "cis_train = []\n",
    "cis_test = []\n",
    "for index, experiment in ope_wis.iterrows():\n",
    "    mean = experiment['phwis']\n",
    "    if experiment['train_test'] == 'train':\n",
    "        n = experiment['n_train']\n",
    "        cis = cis_train\n",
    "    elif experiment['train_test'] == 'test':\n",
    "        n = experiment['n_test']\n",
    "        cis = cis_test\n",
    "    else:\n",
    "        raise ValueError('Only train and test results supported for now')\n",
    "    ci_low, ci_up = utils.var_to_ci_cheb(experiment['var'], mean, n)\n",
    "    ci_low = max(ci_low, -100)\n",
    "    ci_up = min(ci_up, 100)\n",
    "    cis.append([experiment['seed'], experiment['algorithm'], experiment['unsafety_prob'], experiment['norm_scalar'], mean, ci_low, ci_up, experiment['hcope5'], experiment['am']])\n",
    "\n",
    "cis_test = pd.DataFrame(cis_test, columns=['seed', 'algorithm', 'unsafety_prob', 'norm_scalar', 'phwis', 'ci_l', 'ci_u', 'hcope5', 'am'])\n",
    "cis_train = pd.DataFrame(cis_train, columns=['seed', 'algorithm', 'unsafety_prob', 'norm_scalar', 'phwis', 'ci_l', 'ci_u', 'hcope5', 'am'])\n",
    "\n",
    "cis_test['setup'] = cis_test[['algorithm', 'norm_scalar', 'unsafety_prob']].apply(lambda x: '-'.join(map(str, x)), axis=1)\n",
    "cis_train['setup'] = cis_train[['algorithm', 'norm_scalar', 'unsafety_prob']].apply(lambda x: '-'.join(map(str, x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IL-0.0-0 26.479301336357924 42.93725421661811\n",
      "(7.661565760691602, 45.29703691202425)\n",
      "IL-0.0-1 36.464975151706184 4.4401957104150505\n",
      "(34.51900933933106, 38.410940964081306)\n",
      "O-0.0-1 26.828324994378807 1.9676269187419824\n",
      "(25.96599032151751, 27.690659667240105)\n",
      "QL$_D$-0.0-0 -1.1480664552788502 8.48674983363266\n",
      "(-3.7780891489273936, 1.4819562383696931)\n",
      "QL$_D$-0.0-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_D$-0.0025-0 -1.1480664552788502 8.48674983363266\n",
      "(-3.7780891489273936, 1.4819562383696931)\n",
      "QL$_D$-0.0025-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_D$-0.005-0 -0.020527292969565236 0.8724910226279119\n",
      "(-0.2909100937471185, 0.24985550780798804)\n",
      "QL$_D$-0.005-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_D$-0.01-0 0.07693872759292651 1.0702007376891804\n",
      "(-0.25471382280128907, 0.4085912779871421)\n",
      "QL$_D$-0.01-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_D$-0.015-0 0.07693872759292651 1.0702007376891804\n",
      "(-0.25471382280128907, 0.4085912779871421)\n",
      "QL$_D$-0.015-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_D$-0.02-0 0.07693872759292651 1.0702007376891804\n",
      "(-0.25471382280128907, 0.4085912779871421)\n",
      "QL$_D$-0.02-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_D$-0.03-0 -0.09135629589122175 0.5777879472250858\n",
      "(-0.27041134559900093, 0.08769875381655741)\n",
      "QL$_D$-0.03-1 0.0 0.0\n",
      "(nan, nan)\n",
      "QL$_S$-0.0-0 28.36450901308628 48.42095731616643\n",
      "(13.358974611090696, 43.37004341508187)\n",
      "QL$_S$-0.0-1 24.808402149927804 50.59393544304231\n",
      "(2.6350397337763027, 46.981764566079306)\n",
      "QL$_S$-0.0025-0 28.293147196220627 48.43650273572645\n",
      "(13.282795307315848, 43.30349908512541)\n",
      "QL$_S$-0.0025-1 24.812727725535517 50.60460397413113\n",
      "(2.6346897053969194, 46.99076574567411)\n",
      "QL$_S$-0.005-0 28.860597622405397 48.58499361740571\n",
      "(13.804228778096952, 43.916966466713845)\n",
      "QL$_S$-0.005-1 21.31052581988211 51.07540898724586\n",
      "(-1.0738478033622414, 43.69489944312646)\n",
      "QL$_S$-0.01-0 28.820233078748366 48.550190886490206\n",
      "(13.774649514305953, 43.86581664319078)\n",
      "QL$_S$-0.01-1 21.46225060691911 51.08238253209489\n",
      "(-0.9251792509491885, 43.84968046478741)\n",
      "QL$_S$-0.015-0 28.212593058436607 48.689607343908634\n",
      "(13.123804680129473, 43.30138143674374)\n",
      "QL$_S$-0.015-1 21.921503555008236 50.214498555384225\n",
      "(-0.08556636876399537, 43.928573478780464)\n",
      "QL$_S$-0.02-0 28.29822709280146 48.6380678135933\n",
      "(13.225410686922704, 43.37104349868022)\n",
      "QL$_S$-0.02-1 22.038118837505813 50.81507562522022\n",
      "(-0.23216075579875906, 44.308398430810385)\n",
      "QL$_S$-0.03-0 16.06338085005214 55.60708368765715\n",
      "(-1.1691162652248188, 33.2958779653291)\n",
      "QL$_S$-0.03-1 31.09187124025332 45.233533268981084\n",
      "(11.26776549016201, 50.91597699034463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/floris/anaconda3/envs/ventrl/lib/python3.11/site-packages/scipy/stats/_distn_infrastructure.py:2351: RuntimeWarning: invalid value encountered in multiply\n",
      "  lower_bound = _a * scale + loc\n",
      "/home/floris/anaconda3/envs/ventrl/lib/python3.11/site-packages/scipy/stats/_distn_infrastructure.py:2352: RuntimeWarning: invalid value encountered in multiply\n",
      "  upper_bound = _b * scale + loc\n"
     ]
    }
   ],
   "source": [
    "for setup, means in cis_test.groupby('setup')['phwis']:\n",
    "    mean = means.mean()\n",
    "    std = means.std()\n",
    "    print(setup, mean, std)\n",
    "    print(scipy.stats.norm.interval(.95, loc=mean, scale=std/math.sqrt(len(means))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_setup_scalar(row):\n",
    "    rnp = row.to_numpy()\n",
    "    alg, safe_scalar, mixing_scalar = rnp[0], rnp[1], rnp[2]\n",
    "    if alg in {'O', 'IL'}:\n",
    "        return alg\n",
    "    elif alg in {'QL$_D$', 'QL$_S$'}:\n",
    "        return '{}\\nc={}'.format(alg, safe_scalar)\n",
    "    elif alg in 'M':\n",
    "        return '{}\\nc={}'.format(alg, mixing_scalar)\n",
    "\n",
    "def to_setup(row):\n",
    "    rnp = row.to_numpy()\n",
    "    alg, safe_scalar, mixing_scalar = rnp[0], rnp[1], rnp[2]\n",
    "    if alg in {'O', 'IL'}:\n",
    "        return alg\n",
    "    elif alg in {'QL$_D$', 'QL$_S$'}:\n",
    "        return '{}'.format(alg)\n",
    "    elif alg in 'M':\n",
    "        return '{}'.format(alg)\n",
    "\n",
    "def setup_key(setup):\n",
    "    order = pd.Series([float('-inf'),] * len(setup))\n",
    "    order[setup == 'O'] = 0\n",
    "    order[setup == 'IL'] = 1\n",
    "    order[setup.str.contains('QL$_D$')] = setup.str.split('=').str[1].astype('float') * 200 + 1\n",
    "    order[setup.str.contains('QL$_S$')] = setup.str.split('=').str[1].astype('float') * 200 + 2\n",
    "    order[setup.str.contains('M')] = setup.str.split('=').str[1].astype('float') * 200 + 2\n",
    "    return order\n",
    "\n",
    "def algorithm_key(algorithm):\n",
    "    order = pd.Series([float('inf'),] * len(setup))\n",
    "    order[algorithm == 'O'] = 1\n",
    "    order[algorithm == 'IL'] = 2\n",
    "    order[algorithm == 'QL$_D$'] = 3\n",
    "    order[algorithm == 'QL$_S$'] = 4\n",
    "#     order[setup.str.contains('M')] = setup.str.split('=').str[1].astype('float') * 200 + 2\n",
    "    return order\n",
    "\n",
    "def safety_setup(row):\n",
    "    rnp = row.to_numpy()\n",
    "    unsafety_train, unsafety_final = rnp[0], rnp[1]\n",
    "    if unsafety_final == 1.0:\n",
    "        return 'Unsafe'\n",
    "    elif unsafety_final == 0.0 and unsafety_train == 0.0:\n",
    "        return 'Q-function'\n",
    "    elif unsafety_final == 0.0 and unsafety_train == 1.0:\n",
    "        return 'Policy'\n",
    "    else:\n",
    "        raise ValueError('Unknown safety combination {}'.format(rnp))\n",
    "\n",
    "ope_wis['setup'] = ope_wis[['algorithm', 'norm_scalar', 'mixing_prob']].apply(to_setup, axis=1)\n",
    "ope_wis['setup_scalar'] = ope_wis[['algorithm', 'norm_scalar', 'mixing_prob']].apply(to_setup_scalar, axis=1)\n",
    "ope_wis['safety'] = ope_wis[['unsafety_prob_train', 'unsafety_prob']].apply(safety_setup, axis=1)\n",
    "ope_wis['compliance'] = ope_wis.safety\n",
    "ope_wis['compliance'] = ope_wis.compliance.str.replace('Unsafe', 'Unconstr\\'nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Q-function\n",
       "1       Q-function\n",
       "2       Q-function\n",
       "3       Q-function\n",
       "4       Q-function\n",
       "          ...     \n",
       "895    Unconstr'nd\n",
       "896         Policy\n",
       "897     Q-function\n",
       "898    Unconstr'nd\n",
       "899         Policy\n",
       "Name: compliance, Length: 900, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ope_wis.compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1409916/3089285739.py:35: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  plot_data = to_plot[\n",
      "/tmp/ipykernel_1409916/3089285739.py:171: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "def set_size(width_pt, fraction=1, times=1, subplots=(1, 1), buffer=0.0):\n",
    "    \"\"\"Set figure dimensions to sit nicely in our document.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width_pt: float\n",
    "            Document width in points\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt \n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * (1 + buffer) * golden_ratio * (subplots[0] / subplots[1]) \n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "to_plot = ope_wis[ope_wis.norm_scalar == 0.0]\n",
    "plot_algs = list(to_plot.algorithm.unique())\n",
    "# plot_algs.remove('QL')\n",
    "plot_data = to_plot[\n",
    "    ope_wis.algorithm.isin(plot_algs) &\n",
    "    ope_wis.unsafety_prob.isin({0,1})].sort_values('setup', key=setup_key).copy()\n",
    "plot_data.loc[:, 'algorithm'] = plot_data.setup\n",
    "# plot_data = plot_data.sort_values('algorithm', key=algorithm_key)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, sharey=True, figsize=(15,5))\n",
    "hue_order=sorted(plot_data.compliance.unique(), reverse=True)\n",
    "MARKERS = ['^', 'o', 'v', 's']\n",
    "LINESTYLES = ['solid', 'dashed','dotted']\n",
    "\n",
    "\n",
    "subplots= (3,2)\n",
    "fig = plt.figure(figsize=set_size(TEXTWIDTH, fraction=1.0, subplots=subplots, buffer=0.4))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(subplots[0], subplots[1], figsize=set_size(TEXTWIDTH, fraction=1.0, subplots=subplots), sharex='col')\n",
    "# ax[-1][-1].axis('off')\n",
    "# sns.pointplot(data=plot_data[plot_data.train_test == 'train'], x='setup', y='phwis', hue='unsafety_prob', hue_order=hue_order, join=False, dodge=True, ax=ax[0], n_boot=N_BOOT)\n",
    "dodge=0.5\n",
    "errwidth=1.0\n",
    "ax_1 = fig.add_subplot(3,2,1)\n",
    "ax_i = ax_1\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='fqe',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              linestyles=LINESTYLES,\n",
    "              ax=ax_i,\n",
    "              join=False,\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "# ax_i.set_title('FQE')\n",
    "ax_i.set_title('Model-based')\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.set_xlabel('Expected Return')\n",
    "ax_i.set_ylabel('')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,3, sharex=ax_1)\n",
    "plot_data_i = plot_data[(plot_data.train_test == 'test') & (plot_data.ess > 0.0)]\n",
    "# plot_data_i = plot_data[(plot_data.train_test == 'test')]\n",
    "\n",
    "sns.pointplot(data=plot_data_i,\n",
    "              y='algorithm',\n",
    "              x='phwis',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              linestyles=LINESTYLES,\n",
    "              ax=ax_i,\n",
    "              join=False,\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.set_xlabel('Expected Return')\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_title('Inverse Propensity Scoring')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,5, sharex=ax_1)\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='phwdr',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              linestyles=LINESTYLES,\n",
    "              ax=ax_i,\n",
    "              join=False,\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "# ax[2].legend()\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_title('Hybrid')\n",
    "ax_i.set_xlabel('Expected Return')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,2)\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='safety_policy',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              linestyles=LINESTYLES,\n",
    "              ax=ax_i,\n",
    "              join=False,\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.set_xlim(0,1.1)\n",
    "# ax[2].legend()\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_xlabel(r'$P(a \\in A_{\\mathcal{C}})$')\n",
    "ax_i.set_title('Compliance')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,4)\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='ess',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              linestyles=LINESTYLES,\n",
    "              ax=ax_i,\n",
    "              join=False,\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.legend(loc='best',title='', handletextpad=.1)\n",
    "ax_i.set_xscale('symlog')\n",
    "ax_i.set_xlim(-1.0,10e3)\n",
    "# ax[2].legend()\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_xlabel('ESS')\n",
    "ax_i.set_title('Effective sample size')\n",
    "\n",
    "\n",
    "# ax[1].axhline(y=16.717279190924337, color='black')\n",
    "# ax[1].axhline(y=73.3723122454629, color='black')\n",
    "# plt.suptitle('')\n",
    "fig.tight_layout()\n",
    "plt.savefig('/tmp/all_ope.pdf', dpi=1200)\n",
    "# plt.savefig('/tmp/all_ope.png', dpi=1200)\n",
    "plt.savefig('/tmp/all_ope.pgf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1409916/1019887936.py:27: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "q_d = ope_wis[(ope_wis.algorithm == 'QL$_D$')]\n",
    "hue_order=sorted(q_d.compliance.unique(), reverse=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=set_size(TEXTWIDTH, fraction=0.6))\n",
    "\n",
    "ax = sns.pointplot(data=q_d[q_d.train_test == 'test'],\n",
    "              y='fqe',\n",
    "              x='scalar',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              linestyles=LINESTYLES,\n",
    "              join=False,\n",
    "                   ax=ax,\n",
    "              dodge=0.4,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(loc='best',title='', handletextpad=.1)\n",
    "ax.set_ylabel('Expected Return')\n",
    "ax.set_xlabel('$c$')\n",
    "ax.set_title('QL$_D$ with reward shaping')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/shaping.pdf')\n",
    "# plt.savefig('/tmp/shaping.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_filters = (q_d.shaped == False) & (q_d.algorithm == 'QL$_D$')\n",
    "q_d_qsafe = q_d[shared_filters & (q_d.safety == 'Q-function')].sort_values('seed')\n",
    "q_d_psafe = q_d[shared_filters & (q_d.safety == 'Policy')].sort_values('seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)\n",
      "fqe: WilcoxonResult(statistic=209.0, pvalue=1.9073486328125e-06)\n"
     ]
    }
   ],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('fqe: {}'.format(scipy.stats.wilcoxon(q_d_qsafe.fqe, q_d_psafe.fqe, alternative='greater')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = plot_data[plot_data.algorithm == 'O'].sort_values('seed')\n",
    "il_u = plot_data[(plot_data.algorithm == 'IL') & (plot_data.safety == 'Unsafe')].sort_values('seed')\n",
    "il_psafe = plot_data[(plot_data.algorithm == 'IL') & (plot_data.safety == 'Policy')].sort_values('seed')\n",
    "\n",
    "q_d_qsafe = plot_data[(plot_data.algorithm == 'QL$_D$') & (plot_data.safety == 'Q-function') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_d_psafe = plot_data[(plot_data.algorithm == 'QL$_D$') & (plot_data.safety == 'Policy') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_d_u = plot_data[(plot_data.algorithm == 'QL$_D$') & (plot_data.safety == 'Unsafe') & (plot_data.shaped == False)].sort_values('seed')\n",
    "\n",
    "q_s_qsafe = plot_data[(plot_data.algorithm == 'QL$_S$') & (plot_data.safety == 'Q-function') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_s_psafe = plot_data[(plot_data.algorithm == 'QL$_S$') & (plot_data.safety == 'Policy') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_s_u = plot_data[(plot_data.algorithm == 'QL$_S$') & (plot_data.safety == 'Unsafe') & (plot_data.shaped == False)].sort_values('seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)\n",
      "il_u: WilcoxonResult(statistic=209.0, pvalue=0.9999990463256836)\n",
      "il_psafe: WilcoxonResult(statistic=107.0, pvalue=0.5363607406616211)\n",
      "q_d_u: -\n",
      "q_d_qsafe: -\n",
      "q_d_psafe: WilcoxonResult(statistic=0.0, pvalue=0.125)\n",
      "q_s_u: WilcoxonResult(statistic=93.0, pvalue=0.3371114730834961)\n",
      "q_s_qsafe: WilcoxonResult(statistic=80.0, pvalue=0.18413829803466797)\n",
      "q_s_psafe: WilcoxonResult(statistic=128.0, pvalue=0.805811882019043)\n"
     ]
    }
   ],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('il_u: {}'.format(scipy.stats.wilcoxon(il_u.phwis, o.phwis, alternative='less')))\n",
    "print('il_psafe: {}'.format(scipy.stats.wilcoxon(il_psafe.phwis, o.phwis, alternative='less')))\n",
    "print('q_d_u: -')\n",
    "print('q_d_qsafe: -')\n",
    "nonzero_seeds = q_d_psafe[q_d_psafe.phwis !=0].seed\n",
    "print('q_d_psafe: {}'.format(scipy.stats.wilcoxon(q_d_psafe.phwis[q_d_psafe.seed.isin(nonzero_seeds)], o[o.seed.isin(nonzero_seeds)].phwis, alternative='less')))\n",
    "print('q_s_u: {}'.format(scipy.stats.wilcoxon(q_s_u.phwis, o.phwis, alternative='less')))\n",
    "print('q_s_qsafe: {}'.format(scipy.stats.wilcoxon(q_s_qsafe.phwis, o.phwis, alternative='less')))\n",
    "print('q_s_psafe: {}'.format(scipy.stats.wilcoxon(q_s_psafe.phwis, o.phwis, alternative='less')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)\n",
      "il_u: WilcoxonResult(statistic=16.0, pvalue=0.00016117095947265625)\n",
      "il_psafe: WilcoxonResult(statistic=16.0, pvalue=0.00016117095947265625)\n",
      "q_d_u: WilcoxonResult(statistic=210.0, pvalue=1.0)\n",
      "q_d_qsafe: WilcoxonResult(statistic=210.0, pvalue=1.0)\n",
      "q_d_psafe: WilcoxonResult(statistic=210.0, pvalue=1.0)\n",
      "q_s_u: WilcoxonResult(statistic=16.0, pvalue=0.00016117095947265625)\n",
      "q_s_qsafe: WilcoxonResult(statistic=14.0, pvalue=0.0001049041748046875)\n",
      "q_s_psafe: WilcoxonResult(statistic=25.0, pvalue=0.0008449554443359375)\n"
     ]
    }
   ],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('il_u: {}'.format(scipy.stats.wilcoxon(il_u.phwdr, o.phwdr, alternative='less')))\n",
    "print('il_psafe: {}'.format(scipy.stats.wilcoxon(il_psafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_d_u: {}'.format(scipy.stats.wilcoxon(q_d_u.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_d_qsafe: {}'.format(scipy.stats.wilcoxon(q_d_qsafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_d_psafe: {}'.format(scipy.stats.wilcoxon(q_d_psafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_s_u: {}'.format(scipy.stats.wilcoxon(q_s_u.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_s_qsafe: {}'.format(scipy.stats.wilcoxon(q_s_qsafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_s_psafe: {}'.format(scipy.stats.wilcoxon(q_s_psafe.phwdr, o.phwdr, alternative='less')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878     8\n",
       "605    14\n",
       "647    16\n",
       "Name: seed, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ql_qsafe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compare whether the safety criterion should be included in the Q function definition or not\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphwdr: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mwilcoxon(\u001b[43mql_qsafe\u001b[49m\u001b[38;5;241m.\u001b[39mphwdr, ql_psafe\u001b[38;5;241m.\u001b[39mphwdr, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mpvalue))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphwis: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scipy\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mwilcoxon(ql_qsafe\u001b[38;5;241m.\u001b[39mphwis, ql_psafe\u001b[38;5;241m.\u001b[39mphwis, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mpvalue))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ql_qsafe' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('phwdr: {}'.format(scipy.stats.wilcoxon(ql_qsafe.phwdr, ql_psafe.phwdr, alternative='less').pvalue))\n",
    "print('phwis: {}'.format(scipy.stats.wilcoxon(ql_qsafe.phwis, ql_psafe.phwis, alternative='less').pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistic_row(datarow, statistic=np.mean, cols = ['phwis', 'fqe', 'phwdr', 'ess'], prec=0.2):\n",
    "    for c in cols:\n",
    "        if c != 'ess':\n",
    "            loc, (ci_l, ci_u) = utils.bootstrap_ci(datarow[c], stat=statistic, conf=0.95)\n",
    "            print((\" {:\" + str(prec) + \"f} & {:\"+str(prec) +\"f}-{:\"+str(prec)+\"f} &\").format(loc, ci_l, ci_u), end=\" \")\n",
    "        else:\n",
    "            print((\" {:\" + str(prec) + \"f} \").format(statistic(datarow[c])), end=\"\\\\\\\\\\n\")\n",
    "\n",
    "            \n",
    "for stat in [\n",
    "    ope_wis[ope_wis.algorithm == 'O'],\n",
    "    il_unsafe,\n",
    "    il_psafe,\n",
    "    ql_unsafe,\n",
    "    ql_qsafe,\n",
    "    ql_psafe\n",
    "]:\n",
    "    print_statistic_row(stat, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "statistic = np.mean \n",
    "# statistic = np.median\n",
    "print('Observed')\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].phwdr))\n",
    "print('IL-unsafe')\n",
    "print(utils.bootstrap_ci(il_unsafe.phwdr))\n",
    "print(utils.bootstrap_ci(il_unsafe.phwis))\n",
    "print(utils.bootstrap_ci(il_unsafe.fqe))\n",
    "\n",
    "print('IL-psafe')\n",
    "print(utils.bootstrap_ci(il_psafe.phwdr))\n",
    "print(utils.bootstrap_ci(il_psafe.phwis))\n",
    "print(utils.bootstrap_ci(il_psafe.fqe))\n",
    "print('QL-unsafe')\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwis))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].fqe))\n",
    "print('QL-qsafe')\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwis))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].fqe))\n",
    "\n",
    "print('QL-psafe')\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwdr))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwis))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].fqe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?utils.bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = False\n",
    "# statistic = np.mean \n",
    "statistic = np.median\n",
    "print('Observed')\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].fqe, statistic))\n",
    "print('IL-unsafe')\n",
    "print(utils.bootstrap_ci(il_unsafe.phwdr, statistic))\n",
    "print(utils.bootstrap_ci(il_unsafe.phwis, statistic))\n",
    "print(utils.bootstrap_ci(il_unsafe.fqe, statistic))\n",
    "\n",
    "print('IL-psafe')\n",
    "print(utils.bootstrap_ci(il_psafe.phwdr, statistic))\n",
    "print(utils.bootstrap_ci(il_psafe.phwis, statistic))\n",
    "print(utils.bootstrap_ci(il_psafe.fqe, statistic))\n",
    "\n",
    "print('QL-unsafe')\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].fqe, statistic))\n",
    "\n",
    "print('QL-qsafe')\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].fqe, statistic))\n",
    "\n",
    "print('QL-psafe')\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].fqe, statistic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = scipy.stats.bootstrap([ql_unsafe[ql_unsafe.scalar == 0.0].phwdr,], np.mean, confidence_level=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.var_to_sem(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr.var(), len(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_unsafe[ql_unsafe.scalar == 0.0].phwdr.std() / math.sqrt(len(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, ql_unsafe[ql_unsafe.scalar == 0.0].phwdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_rel(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, ql_unsafe[ql_unsafe.scalar == 0.0].phwdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_unsafe[ql_unsafe.scalar == 0.0][['seed','phwdr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, ql_unsafe[ql_unsafe.scalar == 0.0].phwdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(ql_unsafe, ql_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(il_unsafe, ql_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(il_safe, ql_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(il_unsafe, il_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(o, ql_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(o, il_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(o, il_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ope_wis[\n",
    "    (ope_wis.train_test == 'test') & \n",
    "    (ope_wis.algorithm == 'QL') &\n",
    "#     ((ope_wis.unsafety_prob == 0.0) |\n",
    "#      (ope_wis.unsafety_prob == 1.0))\n",
    "#     ((ope_wis.norm_scalar == 0.0) | \n",
    "#      (ope_wis.norm_scalar == .05))\n",
    "    (ope_wis.seed == 5)\n",
    "]\n",
    "\n",
    "# check[['norm_scalar', 'seed', 'mean', 'unsafety_prob']].sort_values(['seed', 'norm_scalar', 'unsafety_prob']).set_index('norm_scalar').pivot(columns=['seed', 'unsafety_prob'])\n",
    "check[['norm_scalar', 'seed', 'phwis', 'unsafety_prob']].sort_values(['seed', 'norm_scalar', 'unsafety_prob']).set_index('unsafety_prob').pivot(columns=['seed', 'norm_scalar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.scalar.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_rel(ql_safe, ql_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(o, ql_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.scalar.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('O:',utils.ci(o), o.mean())\n",
    "print('IL-unsafe:', utils.ci(il_unsafe), il_unsafe.mean())\n",
    "print('IL-safe:', utils.ci(il_safe), il_safe.mean())\n",
    "print('QL-unsafe:', utils.ci(ql_unsafe), ql_unsafe.mean())\n",
    "print('QL-safe:', utils.ci(ql_safe), ql_safe.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
