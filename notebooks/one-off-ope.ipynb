{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Evaluation policy should have some support in behavior policy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m policies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds, evaluation_policy, behavior_policy, \u001b[38;5;241m*\u001b[39mconfig \u001b[38;5;129;01min\u001b[39;00m evaluations:\n\u001b[0;32m--> 128\u001b[0m     mean, var, traj_weights \u001b[38;5;241m=\u001b[39m \u001b[43mope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwis_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehavior_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     phwismean, var, traj_weights \u001b[38;5;241m=\u001b[39m ope\u001b[38;5;241m.\u001b[39mphwis_policy(ds, evaluation_policy, behavior_policy)\n\u001b[1;32m    130\u001b[0m     ois_weights\u001b[38;5;241m.\u001b[39mappend(traj_weights)\n",
      "File \u001b[0;32m~/Documents/vu/mimic-project/ventai/notebooks/ope.py:87\u001b[0m, in \u001b[0;36mwis_policy\u001b[0;34m(dataset, e_policy, b_policy)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mWeighted trajectory-based importance sampling as defined by Sutton & Barto, page 104/105.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m ds \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 87\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_weights\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mois_traj_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ois_value_trajectory(dataset, e_policy, b_policy)\n\u001b[1;32m     89\u001b[0m weights_vals \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micustay_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_weights\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraj_value\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mfirst()\n",
      "File \u001b[0;32m~/Documents/vu/mimic-project/ventai/notebooks/ope.py:22\u001b[0m, in \u001b[0;36mois_traj_weights\u001b[0;34m(dataset, e_policy, b_policy)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mois_traj_weights\u001b[39m(dataset, e_policy, b_policy):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# store ois weight for each state-action pair in the trajectory\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     ds \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 22\u001b[0m     ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mois_weight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mois_sa_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     traj_weights \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124micustay_id\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mois_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m traj_weights\n",
      "File \u001b[0;32m~/Documents/vu/mimic-project/ventai/notebooks/ope.py:13\u001b[0m, in \u001b[0;36mois_sa_weights\u001b[0;34m(dataset, e_policy, b_policy)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mois_sa_weights\u001b[39m(dataset, e_policy, b_policy):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# definition ois weights\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#     ois_weights = e_policy / b_policy\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ((b_policy \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m&\u001b[39m (e_policy \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m))\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation policy should have some support in behavior policy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     pi_b_as \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: b_policy[x\u001b[38;5;241m.\u001b[39mstate, x\u001b[38;5;241m.\u001b[39maction_discrete], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     pi_e_as \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: e_policy[x\u001b[38;5;241m.\u001b[39mstate, x\u001b[38;5;241m.\u001b[39maction_discrete], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Evaluation policy should have some support in behavior policy"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from collections.abc import Iterable\n",
    "import functools\n",
    "import itertools\n",
    "import operator\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import numpy_ext as npe\n",
    "import math\n",
    "import random\n",
    "from pprint import pprint\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import poisson\n",
    "from scipy.sparse import hstack, vstack, csr_matrix\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import utils\n",
    "import safety\n",
    "import ope\n",
    "\n",
    "import sys\n",
    "\n",
    "from config import demographics, vital_sign_vars, lab_vars, treatment_vars, vent_vars, guideline_vars, ffill_windows_clinical, SAMPLE_TIME_H\n",
    "from config import fio2_bins, peep_bins, tv_bins\n",
    "\n",
    "seed = 3\n",
    "unsafety_prob = 0.0\n",
    "shaping = 'unshaped'\n",
    "\n",
    "test_set_file = 'data/test_unshaped_traj_{}.csv'\n",
    "train_set_file = 'data/train_unshaped_traj_{}.csv'\n",
    "q_fname = 'models/peine_mc_{}_0.0_q_table_{}.bin'\n",
    "\n",
    "greedy_policy_file = 'models/mcp_greedy_policy_{}{}.bin'\n",
    "sm_policy_file = 'models/mcp_softmax_policy_{}_{}_0.0.bin'\n",
    "behavior_policy_train_file = 'models/clinicians_policy_train_{}{}.bin'\n",
    "behavior_policy_test_file = 'models/clinicians_policy_test_{}{}.bin'\n",
    "behavior_policy_file = 'models/clinicians_policy_train_test_{}{}.bin'\n",
    "\n",
    "all_var_types = [\n",
    "    vital_sign_vars,\n",
    "    lab_vars,\n",
    "    treatment_vars,\n",
    "    vent_vars,\n",
    "    guideline_vars,\n",
    "]\n",
    "all_vars = functools.reduce(operator.add, all_var_types)\n",
    "\n",
    "def add_traj_return(dataset):\n",
    "    return_set = dataset.copy()\n",
    "    return_set['traj_reward'] = np.nan\n",
    "    return_set.loc[return_set.mort90day == 't', 'traj_reward'] = -100\n",
    "    return_set.loc[return_set.mort90day == 'f', 'traj_reward'] = 100\n",
    "    return_set['traj_return'] = (.99 ** return_set['traj_len']) * return_set['traj_reward']\n",
    "    return return_set\n",
    "\n",
    "def add_scaled_traj_return(dataset):\n",
    "    return_set = dataset.copy()\n",
    "    return_set['traj_reward'] = np.nan\n",
    "    return_set.loc[return_set.mort90day == 't', 'traj_reward'] = 0\n",
    "    return_set.loc[return_set.mort90day == 'f', 'traj_reward'] = 1\n",
    "    return_set['traj_return'] = (.99 ** return_set['traj_len']) * return_set['traj_reward']\n",
    "    return return_set\n",
    "\n",
    "def add_traj_len(dataset):\n",
    "    assert dataset.traj_count.isna().sum() == 0\n",
    "    return_set = dataset.copy()\n",
    "    return_set['traj_len'] = return_set.groupby('icustay_id')['traj_count'].transform('max')\n",
    "    return_set['traj_len'] = return_set['traj_len'] + 1\n",
    "    return return_set\n",
    "\n",
    "def postprocess(dataset):\n",
    "    return add_traj_return(add_traj_len(dataset))\n",
    "\n",
    "np.random.seed(seed)\n",
    "test_set = postprocess(pd.read_csv(test_set_file.format(seed)))\n",
    "train_set = postprocess(pd.read_csv(train_set_file.format(seed)))\n",
    "\n",
    "q_file = joblib.load(q_fname.format(shaping, seed))\n",
    "q_table_nan = q_file['model']\n",
    "q_table = np.nan_to_num(q_table_nan, 0.0)\n",
    "q_table_neg = q_table_nan.copy()\n",
    "q_table_neg[q_table_neg == 0.0] = float('-inf')\n",
    "t = 1.0\n",
    "q_table_nan[q_table_nan == 0.0] = np.nan\n",
    "\n",
    "assert test_set.traj_reward.isna().sum() == 0\n",
    "assert train_set.traj_reward.isna().sum() == 0\n",
    "behavior_policy = utils.repair_policy_uniform(joblib.load(behavior_policy_file.format(seed,'')))\n",
    "behavior_train_policy = joblib.load(behavior_policy_train_file.format(seed,''))\n",
    "behavior_test_policy = joblib.load(behavior_policy_test_file.format(seed,''))\n",
    "behavior_safe_train = safety.repaired_safe(behavior_train_policy, behavior_train_policy)\n",
    "sm_unsafe = joblib.load(sm_policy_file.format(seed, shaping, unsafety_prob))\n",
    "if shaping == 'unshaped':\n",
    "    shaping_scalar = 0.0\n",
    "evaluations = [\n",
    "    (train_set, sm_unsafe, behavior_policy, 'train', 'softmax', shaping, shaping_scalar, 'unsafe', seed),\n",
    "    (test_set, sm_unsafe, behavior_policy, 'test', 'softmax', shaping, shaping_scalar, 'unsafe', seed),\n",
    "]\n",
    "if shaping == 'unshaped':\n",
    "    evaluations += [\n",
    "        (train_set, behavior_train_policy, behavior_train_policy, 'train', 'observed', shaping, shaping_scalar, 'unsafe', seed),\n",
    "        (test_set, behavior_test_policy, behavior_test_policy, 'test', 'observed', shaping, shaping_scalar, 'unsafe', seed),\n",
    "        (train_set, behavior_train_policy, behavior_policy, 'train', 'behavior', shaping, shaping_scalar, 'unsafe', seed),\n",
    "        (test_set, behavior_train_policy, behavior_policy, 'test', 'behavior', shaping, shaping_scalar, 'unsafe', seed),\n",
    "        (train_set, behavior_safe_train, behavior_policy, 'train', 'behavior', shaping, shaping_scalar, 'safe', seed),\n",
    "        (test_set, behavior_safe_train, behavior_policy, 'test', 'behavior', shaping, shaping_scalar, 'safe', seed),\n",
    "    ]\n",
    "ois_weights = []\n",
    "means = []\n",
    "phwis_means = []\n",
    "policies = []\n",
    "for ds, evaluation_policy, behavior_policy, *config in evaluations:\n",
    "    mean, var, traj_weights = ope.wis_policy(ds, evaluation_policy, behavior_policy)\n",
    "    phwismean, var, traj_weights = ope.phwis_policy(ds, evaluation_policy, behavior_policy)\n",
    "    ois_weights.append(traj_weights)\n",
    "    means.append(mean)\n",
    "    phwis_means.append(phwis_means)\n",
    "    policies.append((evaluation_policy, behavior_policy))\n",
    "    #am = ope.am(ds, evaluation_policy, behavior_policy, delta=0.05)\n",
    "    #hcope5 = ope.hcope(ds, evaluation_policy, behavior_policy, delta=0.05, c=5)\n",
    "    am, hcope5 = np.nan, np.nan\n",
    "    ess = (traj_weights > 0.0).sum()\n",
    "    print(','.join(map(str, (*config, mean, phwismean, var, ess))))\n",
    "    # TODO: write result to file with config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_set = train_set.copy()\n",
    "return_set.traj_reward = np.nan\n",
    "return_set.loc[return_set.mort90day == 't', 'traj_reward'] = 0\n",
    "return_set.loc[return_set.mort90day == 'f', 'traj_reward'] = 1\n",
    "return_set['traj_return'] = (.99 ** return_set['traj_len']) * return_set['traj_reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_set.traj_reward.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.mort90day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(behavior_policy[behavior_policy != 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.state_action_id.value_counts().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.state.value_counts().hist(bins=400)\n",
    "plt.title('Train set state visitations')\n",
    "plt.show()\n",
    "\n",
    "train_set.state_action_id.value_counts().hist(bins=140)\n",
    "plt.title('Train set state-action visitations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_result = 1 # index of solution\n",
    "e_policy, b_policy = policies[sm_result]\n",
    "train_test = train_set if sm_result % 2 == 0 else test_set\n",
    "train_test_label = 'train' if sm_result % 2 == 0 else 'test'\n",
    "traj_weights = ois_weights[sm_result]\n",
    "sa_weights = ope.ois_sa_weights(train_test, e_policy, b_policy)\n",
    "weight_cutoff = .0001 / len(traj_weights)\n",
    "# weight_cutoff = 0.0 #.01 / len(traj_weights)\n",
    "train_test['ois_weights_plot'] = traj_weights\n",
    "train_test['sa_weights'] = sa_weights\n",
    "traj_returns = train_test.groupby('icustay_id')['traj_return'].first()\n",
    "weights_returns = pd.DataFrame({'traj_return': traj_returns, 'ois_weight': traj_weights})\n",
    "weights_returns['weighted_return'] = weights_returns.traj_return * weights_returns.ois_weight\n",
    "incl_trajs = traj_weights[traj_weights > weight_cutoff]\n",
    "g = sns.histplot(ois_weights[sm_result], bins=500)\n",
    "g.set(xscale='log', yscale='log')\n",
    "plt.title('{}, weights>{:.2E}={}={:.2f}%,seed={},ope={:.1f}'.format(train_test_label, weight_cutoff,(traj_weights > weight_cutoff).sum(), (traj_weights > 0.0).mean() * 100, seed, means[sm_result]))\n",
    "plt.xlabel('OIS weight')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=traj_weights)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x=traj_weights[traj_weights > weight_cutoff])\n",
    "plt.show()\n",
    "\n",
    "plot_returns = weights_returns[weights_returns.ois_weight > weight_cutoff]\n",
    "g = sns.scatterplot(plot_returns, x='traj_return', y='ois_weight', alpha=.4)\n",
    "g.set(yscale='log')\n",
    "plt.xlabel('Trajectory return')\n",
    "plt.ylabel('OIS weight')\n",
    "plt.show()\n",
    "\n",
    "(train_test.groupby('icustay_id')['mort90day'].first() == 'f').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmax(q_table, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_policy = policies[4][0]\n",
    "m = .5\n",
    "mixed_policy = ((m* il_policy + (1-m)*e_policy))\n",
    "mixed_safe = safety.repaired_safe(mixed_policy, behavior_train_policy)\n",
    "ope.wis_policy(ds, mixed_policy, behavior_policy)\n",
    "ope.phwis_policy(ds, mixed_policy, behavior_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope.wis_policy(ds, mixed_policy, behavior_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_returns.weighted_return.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traj_weights.idxmax(), traj_weights.max(), \n",
    "# train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_test.icustay_id == 248077).any()\n",
    "train_test[train_test.icustay_id == 248077][['state', 'action_discrete']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['e_policy_prob'] = train_test.apply(lambda x: e_policy[x.state, x.action_discrete], axis=1)\n",
    "train_test['b_policy_prob'] = train_test.apply(lambda x: b_policy[x.state, x.action_discrete], axis=1)\n",
    "train_test['il_policy_prob'] = train_test.apply(lambda x: il_policy[x.state, x.action_discrete], axis=1)\n",
    "train_test['q_value'] = train_test.apply(lambda x: q_table_nan[x.state, x.action_discrete], axis=1)\n",
    "\n",
    "train_test[train_test.icustay_id == 248077][['state', 'action_discrete', 'sa_weights', 'b_policy_prob', 'e_policy_prob', 'il_policy_prob', 'q_value']]\n",
    "\n",
    "# train_set.state.value_counts()[479]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_policy_neg = il_policy.copy()\n",
    "il_policy_neg[il_policy_neg == 0.0] = float('-inf')\n",
    "temperature = 1e5\n",
    "il_trans = scipy.special.softmax(il_policy_neg / temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, (p_e, p_il, p_m, q) in enumerate(zip(e_policy[343,:], il_policy[343,:], mixed_policy[343,:], q_table_nan[343,:])):\n",
    "    if p_e > 0 or p_il > 0:\n",
    "        print(\"{:4d}: {:.4f} {:.4f} {:.4f} {:.4f} {}\".format(a, p_e, p_il, p_m, q, safety.action_id_compliance[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(train_set.groupby('state').icustay_id.nunique(), bins=train_set.groupby('state').icustay_id.nunique().max())\n",
    "plt.xlabel('# trajectories')\n",
    "plt.title('Distribution of states over train trajectories')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(train_set.groupby('state_action_id').icustay_id.nunique(), bins=train_set.groupby('state_action_id').icustay_id.nunique().max())\n",
    "plt.xlabel('# trajectories')\n",
    "plt.title('Distribution of state-action tuples over train trajectories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(test_set.groupby('state').icustay_id.nunique(), bins=test_set.groupby('state').icustay_id.nunique().max())\n",
    "plt.xlabel('# trajectories')\n",
    "plt.title('Distribution of states over test trajectories')\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(test_set.groupby('state_action_id').icustay_id.nunique(), bins=test_set.groupby('state_action_id').icustay_id.nunique().max())\n",
    "plt.xlabel('# trajectories')\n",
    "plt.title('Distribution of state-action tuples over test trajectories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(train_set.groupby('state').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9741615392822848"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(safety)\n",
    "safety.state_compliance_clinical(test_set, safety.avg_clinical_timestep).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~(test_set.ph_imp_scaled_impknn_unscaled > 7.2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020130170359568943"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "566 / test_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021718297036344904"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~(train_set.ph_imp_scaled_impknn_unscaled > 7.2)).sum() / train_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((e_policy == 0) & (il_policy >= 1e-6)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, (p_e, p_il, p_m, q) in enumerate(zip(e_policy[393,:], il_policy[393,:], mixed_policy[393,:], q_table_nan[393,:])):\n",
    "    if p_e > 0 or p_il > 0:\n",
    "        print(\"{:4d}: {:.4f} {:.4f} {:.4f} {:.4f} {}\".format(a, p_e, p_il, p_m, q, safety.action_id_compliance[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.groupby('state')['icustay_id'].nunique()[294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.state_action_id.value_counts()['343-191']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[(train_set['state'] == 112)].action_discrete.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(train_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_policy[294,191], b_policy[294,191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.groupby('state')['icustay_id'].nunique()[294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_weights[traj_weights.index == 252599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_weights.sort_values(ascending=False).index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set['icustay_id'] == 252599][demographics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.vent_duration_h.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[train_set['icustay_id'] == 201896]['bun_imp_scaled_impknn_unscaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['elixhauser_vanwalraven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test[train_test.icustay_id == 201896][['state', 'action_discrete']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_policy[241,183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_train_policy[241,183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.state.value_counts()[241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weights_returns[weights_returns.ois_weight < 10e5]), len(weights_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outlier = weights_returns[weights_returns.ois_weight < 10e5]\n",
    "(non_outlier.traj_return * non_outlier.ois_weight).sum() / non_outlier.ois_weight.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(non_outlier.traj_return * (non_outlier.ois_weight / non_outlier.ois_weight.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(non_outlier.traj_return * (non_outlier.ois_weight / non_outlier.ois_weight.sum())).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_returns = weights_returns[weights_returns.ois_weight > weight_cutoff]\n",
    "g = plt.scatter(x=weights_returns['traj_return'], y=weights_returns['ois_weight'], alpha=.4)\n",
    "# g.set(yscale='log')\n",
    "plt.xlabel('Trajectory return')\n",
    "plt.ylabel('OIS weight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set.groupby('icustay_id')['mort90day'].first() == 't').mean()\n",
    "(test_set.groupby('icustay_id')['mort90day'].first() == 't').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_set[test_set.icustay_id.isin(incl_trajs.index)].groupby('icustay_id')['mort90day'].first() == 't').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ois_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ois_weights[1] > 0.0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(traj_weights > (1/len(traj_weights))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
